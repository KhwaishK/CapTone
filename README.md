# ğŸ–¼ï¸ AI Captioning & Rephrasing Tool

This project generates captions for images using **BLIP (Bootstrapped Language Image Pretraining)** and then rephrases them into different tones using **LLaMA 3.1**, with hashtag generation powered by **KeyBERT**.  
It also includes model evaluation on a mini COCO dataset subset, using **BLEU scores** for caption quality assessment.

---

## ğŸš€ Live Demo

ğŸ¯ Try the live app here:  
ğŸ‘‰ [**Hugging Face Demo**](https://huggingface.co/spaces/KhwaishK/CapTone)

---

## ğŸ“¸ Features

- ğŸ§  **Automatic Image Captioning** using Salesforce BLIP model  
- ğŸ·ï¸ **Hashtag Generation** using KeyBERT keyword extraction  
- âœï¸ **Tone Rephrasing** with LLaMA 3.1 (Funny, Professional, Poetic, and Marketing/Ad tones)  
- ğŸ§ª **Model Evaluation** on a mini COCO dataset with BLEU scores  
- ğŸ–¥ï¸ **Streamlit Web App** for easy user interaction  

---

## ğŸ§© Project Structure
```graphql
ğŸ“¦ AI-Captioning-Rephrasing-Tool
â”‚
â”œâ”€â”€ app.py                     # Streamlit-based user interface
â”œâ”€â”€ pipeline.py                # Core pipeline: captioning, hashtags, rephrasing
â”œâ”€â”€ prepare_mini_dataset.py    # Script to create a mini COCO validation dataset
â”œâ”€â”€ model_testing.py           # Evaluates BLIP model performance on mini dataset (BLEU)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ annotations/           # COCO-style annotation JSONs
â”‚   â”œâ”€â”€ mini_val2014/          # Subset of COCO validation images
â”‚   â””â”€â”€ samples/               # Sample images for testing
â”‚
â”œâ”€â”€ params.yaml                # Configuration for model paths, UI options, and parameters
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Setup
### 1ï¸âƒ£ Clone the repository 
```bash
git clone https://github.com/<your-username>/AI-Captioning-Rephrasing-Tool.git
cd AI-Captioning-Rephrasing-Tool
```

---

